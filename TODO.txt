To do:
    Presentatie opbouwen vanaf het begin
        Verhaal van afgelopen meeting er in verwerken
        Zodra af, de plots er in zetten

    LogS van Clayton - sJoe KL tuned werkt niet
        Same data is used for tuning & scoring --> sJoe is over-fitted
        DM stat is soms zero variance -> zorgt dit voor verkeerde rej_freq? ; komt dit door te klein score verschil door afronden?
        RuntimeWarning: divide by zero encountered in scalar divide (1.0 - p_R) * np.log((1.0 - p_R) / (1.0 - f_R))

        In KL test checken kwam het er op neer dat de CS en CLS niet werken
        Lijkt er op dat misschien de local(ized) KL divergences niet correct zijn
            check met de 2025 paper
        Lijkt er op dat het misschien aan de indicator formule ligt --> X
            je kan niet als je op de marginals sum je quantile zet deze ook gebruiken voor de pits sum
            dat zou alleen zo zijn als de marginals uniform zijn en PIT transform een linear transform is
            Goede manier zou zijn:
                generate PITs, convert naar marginals, compute sum & find q_0.05 (kan analytically)
                kijk naar de PIT samples die voor X + Y < q_0.05 zorgen, geef deze PIT sample pairs weight 1 en anders 0

    Bivariate bonferroni bounds?

To do morgen:
    Fix het tweede deel van de simulation die nu kapot lijkt te zijn

Boundary uncertainty extension:
    Maak de restriction transformation met een andere copula dan de f of g voor size en power test credibility (Mitchell & Wealle example)
    Kijk naar andere weight function dan I

Simulation study:
    Repeat de 2010 onderzoek van diks et al, maar gebruik nu de true u'tjes ipv ecdf based als 'echte' gebruiken (size en power vergelijken)
        --> score differences tussen de symmetricaly misspecified f en g zijn distributed rond 1 ipv 0
        --> kijk wat diks et al study doet met de forecasted u en de rolling window -> rolling misschien niet nodig bij mijn versie???
	    --> Kijk hoe fitten van de andere copulas effect heeft op empirical??? (true is bb7 en nu gebruiken we ook bb7 om de boundary te bekijken)

Scriptie meeting 15-5:
    Bij schatten van de u_hats eerste keer worden ze in 2025 paper daarna gebruikt als de echte u'tjes. Als je die u'tjes al zet van tevoren weet je wat de echte zijn. Je kan dan de size en power plots maken met de echte utjes en met de u_hats gebruikt als echte u'tjes. Dan kijken wat het verschil is op de size en power plots.
    Je moet de boundry transformation niet laten afhangen van de copula die je kiest voor je f of g omdat je anders met twee maten meet (als a wisselt tussen f en p en tussen g en p). De boundary moet door een derde copula transformed worden.
        Er is dan dus eigenlijk geen true & waar kan je de bonferroni bounds op zetten?
    Vraag ramon naar hoe hij de numerical integral doet
    Hangt het q'tje nu ook niet af van de f of g? --> maakt waarschijnlijk niet uit

Code algemeen:
	Als too many configs maak dan een class of een namespace
	Cache results of BB1 PDF evaluations over large u arrays.
        Consider vectorized PDF evaluation in R using BiCopPDF() once over a full sample batch.
        Investigate whether BB1 copula samples and densities can be evaluated once and reused.

Scriptie algemeen:
BLIJF SCHRIJVEN IN OVERLEAF
    1. Maak methodologie robuust -> #DONE# begin bij transcriben van de meeting
    2. Maak de collection van papers om te citeren groter (zotero), heb al een aantal gevonden met chat, vind image recog paper
    3. Stop notes in markdown in de repository voor future reference
    4. Bekijk volledige code van Ramon en importeer functies om te gebruiken
    5. Gebruik alle info om de methodologie te maken in code



Notes/vragen:
    Als ik tGARCH(1,1) marginals wil met bb7_copula dependence als true moet ik inverse ecdf gebruiken op de innovations van een simulated tGARCH(1,1)
        Dan komt er al uncertainty door de ecdf bij kijken.
        Alleen als ik een analytical inverse CDF kan gebruiken zoals voor gewoon student t innovations dan heb ik geen uncertainty
            Gebruik inverse ECDF van mega sample om quantile function te maken (mogelijk deze smoothen)
        Is het wel nodig om tGARCH(1,1) marginals te gebruiken in deze simulation study, want de copula vraagt om standardized residuals?
        Als we de residuals van de tGARCH standardizen dan krijg je gewoon student-t distributed marginals die je gebruikt???
        GARCH deel heeft te maken met time dependence, niet cross sectional wat volgens mij alleen zou worden bekeken in deze simulation setup.
        Overschakelen op student-t marginals en analytical inverse CDF?

    Wat zijn normale waardes die de copula density aanneemt wanneer het likely is dat er joint dependence is?
        --> Lijkt me dat 1 independence is en dan 0-1 unlikely en 1+ likely, kan infinite worden

    Wat is het numerically integraten en waarom is dit belangrijk?
        Stel grid is op [0,1]^2 en 300x300 dan heeft elke cell oppervlakte (1/300)^2. Moet deze constant ook keer de uiteindelijke sum (integral approximation)
        Waarom was dit zo een issue volgens ramon?

    Moet ik als ik de ECDF based regions maak en bootstrap/simulation doe de y1 en y2 gebruiken die uit true marginals + true copula komen en dan daar de copula of interest op fitten en dan een nieuwe y series maken?
        Of moet ik gewoon y1 en y2 uit de student-t halen zoals de true en dan gelijk een copula of interest daar op toepassen om daarvan y series met de dependence van die copula te krijgen en dan op een manier vergelijken met de true dependence copula?
        Moet ik de copula of interest fitten? of kan ik gewoon parameters zetten? fitten lijkt me handiger richting empirisch nut

    Moet ik uberhaupt kijken naar smoothing van ECDF door quantile regression of kernel interpolation. Of is dat alleen handig als we een percentile willen zoeken?

PLOT CDF
Compare first innovations (ARMA-GARCH vb (V)AR(1) SCOMDY) vs residuals effect on the ECDF vs ORACLE plots ()
Lastly introduce boundary uncertainty for (innov +( ECDF or ORACLE )) or (reside + (ECDF or oracle))
Robustness checks at end of paper
Write on the effect of correctly choosing which model to estimate (vb true = AR1, but estimated is AR2) -> also ECDF vs inverse of AR(1) if you assume AR(1) is true
Slides must be on combinations of uncertainties in the models
In slides show emperical u vs oracle u (show multiple estimated u lines)

Size discrepancy plots:
    Lijkt of de CS size discrepancy totaal niet klopt.
    De size discrepancies zijn allemaal op een grid van 0.01? hoort volgens mij veel meer te verschillen door de rejection rate
    De 95% point-wise significance intervals moeten worden laten zien ook.
    Vraag chat ipv alleen codex
    Zoek uit wat te doen met de rolling window??? kutzooi
    What does score_vectors do in simulate_one_rep
        maybe changing this broke the point-wise score calc